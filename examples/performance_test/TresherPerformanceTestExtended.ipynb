{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install thresher-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import thresher\n",
    "import time\n",
    "\n",
    "t = thresher.Thresher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently supported algorithms:\n",
      "['auto', 'ls', 'sgd', 'gen', 'grid', 'sgrid']\n"
     ]
    }
   ],
   "source": [
    "print('Currently supported algorithms:')\n",
    "print(t.get_supported_algorithms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the data, unpack the milion_samples.7z file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('milion_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Read 1000000 rows of data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Read {len(data)} rows of data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.974296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.983075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.759452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual_label     score\n",
       "0             1  0.974296\n",
       "1             1  0.983075\n",
       "2             0  0.759452\n",
       "3             0  0.089109\n",
       "4             1  0.984881"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = thresher.Thresher(progress_bar=False, \n",
    "                      labels=(0,1),\n",
    "                      algorithm_params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process took 0.8044310000000001 seconds and gave result of 0.5162577102954293\n",
      "Process took 0.7930709999999999 seconds and gave result of 0.5167630106487863\n",
      "Process took 0.8964840000000005 seconds and gave result of 0.5175735180550672\n",
      "Process took 0.7283390000000001 seconds and gave result of 0.5162577102954293\n",
      "Process took 0.7484799999999998 seconds and gave result of 0.5162577102954293\n",
      "Process took 0.725797 seconds and gave result of 0.5162577102954293\n",
      "Process took 0.7413000000000007 seconds and gave result of 0.5162577102954293\n",
      "Process took 1.0152769999999993 seconds and gave result of 0.5177489522235028\n",
      "Process took 1.5296220000000016 seconds and gave result of 0.5169261655096206\n",
      "Process took 0.9941510000000005 seconds and gave result of 0.5173678563273036\n",
      "Process took 1.4019980000000007 seconds and gave result of 0.5169806044302316\n",
      "Process took 0.7238410000000002 seconds and gave result of 0.5162577102954293\n",
      "Process took 0.8055050000000001 seconds and gave result of 0.5170534038854273\n",
      "Process took 0.9086189999999998 seconds and gave result of 0.5173462066031852\n",
      "Process took 0.8634769999999996 seconds and gave result of 0.5168771304468545\n",
      "Process took 0.9396470000000008 seconds and gave result of 0.5178525398660359\n",
      "Process took 1.2338260000000005 seconds and gave result of 0.5168720305503722\n",
      "Process took 0.9751580000000004 seconds and gave result of 0.516778154220663\n",
      "Process took 1.0238230000000001 seconds and gave result of 0.5168709846317125\n",
      "Process took 1.1581669999999988 seconds and gave result of 0.5179601248995134\n",
      "Process took 0.9226489999999998 seconds and gave result of 0.5173067865844054\n",
      "Process took 0.8819100000000013 seconds and gave result of 0.5176836326218924\n",
      "Process took 0.9230339999999977 seconds and gave result of 0.518090490038259\n",
      "Process took 1.0668229999999994 seconds and gave result of 0.5180881911960988\n",
      "Process took 0.9506529999999991 seconds and gave result of 0.5172886600568737\n"
     ]
    }
   ],
   "source": [
    "for _ in range(25):\n",
    "    s_time = time.process_time()\n",
    "    result = t.optimize_threshold(data.score.values, data.actual_label.values)\n",
    "    elapsed_time = time.process_time() - s_time\n",
    "    print(f'Process took {elapsed_time} seconds and gave result of {result}')\n",
    "    results.append((elapsed_time, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean cpu time: 0.9502432800000001 mean result: 0.5170789881827352'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Mean cpu time: {np.mean([_[0] for _ in results])} mean result: {np.mean([_[1] for _ in results])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
